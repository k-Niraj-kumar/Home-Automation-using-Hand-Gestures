Home Automation using Hand Gestures and Voice Commands

This project aims to provide a hands-free way to control home appliances using hand gestures and voice commands. It utilizes computer vision techniques with OpenCV and the cvzone library to detect hand gestures, and the Whisper speech recognition model to understand voice commands. The project also includes an Arduino Uno board to control the connected appliances.

Summary

The home automation system combines computer vision and speech recognition techniques to provide a natural and intuitive way to control home appliances. By leveraging hand gesture detection and voice command recognition, users can interact with the system in a hands-free manner, enhancing convenience and accessibility.
The system is built using Python and OpenCV for computer vision tasks, the cvzone library for hand tracking and gesture detection, and the Whisper model for speech recognition. The recognized gestures and voice commands are then translated into instructions and sent to an Arduino Uno board, which is responsible for controlling the connected appliances, such as lights, fans, and TVs.
The project demonstrates the integration of various technologies, including computer vision, speech recognition, and hardware control, to create a seamless and intelligent home automation solution.
